# Conceptual

## 1

The null hypothesis that the P-values in Table 3.4 (reproduced below) are calculated on is that coefficients to all the variables in the model (TV, Radio and Newspaper) are zero. That is... $$H_0:~~\beta_{tv} = \beta_{radio} = \beta_{newspaper} = 0$$
and the alternate hypothesis is at least one of the coefficients is non-zero... $$H_A:~~\beta_{tv},~~\beta_{radio}~~or~~\beta_{newspaper} â‰  0$$

The conclusions that can be drawn from the P-values in the table are that *TV* and *Radio* have some relationship with *Sales* with practically complete certainty (the probability of observing those t-statistic's by chance given the null hypotheis is less than 0.01%). On the other hand, given the null hypothesis, we would expect to observe a t-statistic greater than or equal to that of *Newspaper's* 85.99% of the time, and thus we fail to reject the null hypothesis that *Newspaper* has an affect on *Sales.*


```{r, echo = FALSE}
library(knitr)
df <-  data.frame(Variable = c("Intercept",
                               "TV",
                               "radio",
                               "Newspaper"),
                  Coefficient = c("2.939",
                                  "0.046",
                                  "0.189",
                                  "-0.001"),
                  Std_Error = c("0.3119",
                                 "0.0014",
                                 "0.0086",
                                 "0.0059"),
                  t_statistic = c("9.42",
                                  "32.81",
                                  "21.89",
                                  "-0.18"),
                  p_value = c("< 0.0001",
                              "< 0.0001",
                              "< 0.0001",
                              "0.8599")
                  )
kable(df)
```


## 2

The main difference between the *KNN classifier* and *KNN regression* methods is that the *KNN classifier* outputs a qualitative prediction and *KNN regression* ouputs a quantitative prediction.

Mathematically, *KNN classification* takes the K nearest training observations to test obersvation x~0~, and takes a majority vote on which class x~0~ will be. For example, if you set *K = 5*, and you have two possible classes, *A* or *B*, *KNN classifcation* takes the 5 training observations closest to your test observation x~0~, say 3 *A*'s and 2 *B*'s, and classifies x~0~ as *A* because there are more *A*'s in the 5 nearest neighbors than *B*'s.

*KNN regression* takes the *average* of the K nearest neighbors' *quantitative output*. For example, again using the example where *K = 5*, if the 5 training observations closest to x~0~ have respective response values of 16, 22, 14, 24 and 18, then *KNN regression* takes their average and gives the test observation x~0~ that value...$$\frac{16+22+14+24+18}{5} = 18.8 = y_0$$

## 3

To answer this question, the first step I took was to write out and simplify the model:$$\hat{y_i}~=~\hat{\beta_o}~+~\hat{\beta_1}X_1~+~\hat{\beta_2}X_2~+~\hat{\beta_3}X_3~+~\hat{\beta_4}X_4~+~\hat{\beta_5}X_5$$Which, rewritten to express the interaction terms is:$$\hat{y_i}~=~\hat{\beta_o}~+~\hat{\beta_1}X_1~+~\hat{\beta_2}X_2~+~\hat{\beta_3}X_3~+~\hat{\beta_4}X_1X_2~+~\hat{\beta_5}X_1X_3$$Now, X~3~ is a binary variable, which means we can "split" this equation into two separate equations, based on the value of X~3~, where a value of 1 = Female and 0 = Male. Thus:$$\hat{y_i}~=~\hat{\beta_o}~+~\hat{\beta_1}X_1~+~\hat{\beta_2}X_2~+~\hat{\beta_3}~+~\hat{\beta_4}X_1X_2~+~\hat{\beta_5}X_1X_3~~~if~x_i~is~Female$$$$\hat{y_i}~=~\hat{\beta_o}~+~\hat{\beta_1}X_1~+~\hat{\beta_2}X_2~+~0~+~\hat{\beta_4}X_1X_2~+~\hat{\beta_5}X_1X_3~~~if~x_i~is~Male$$X~5~ is an interaction term between Gender and GPA, so if Gender = Male (that is to say X~3~ = 0) we can rewrite the above Male equation as:$$\hat{y_i}~=~\hat{\beta_o}~+~\hat{\beta_1}X_1~+~\hat{\beta_2}X_2~+~0~+~\hat{\beta_4}X_1X_2~+~0~~~if~x_i~is~Male$$And the Female equation, where X~3~ = 1, becomes:$$\hat{y_i}~=~\hat{\beta_o}~+~\hat{\beta_1}X_1~+~\hat{\beta_2}X_2~+~\hat{\beta_3}~+~\hat{\beta_4}X_1X_2~+~\hat{\beta_5}X_1~~~if~x_i~is~Female$$
